# -*- coding: utf-8 -*-
"""Africa

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d5nRE-PHRXsNvsdt77szeIjeU0ig8hjj
"""

import numpy as np
import pandas as pd
from math import sqrt

import matplotlib.pyplot as plt

import statsmodels.api as sm
import statsmodels.stats as stats
from scipy.stats import pearsonr
from lmfit import Parameters, minimize # package to apply NLS
from statsmodels.tsa.arima_model import ARIMA

"""# Forecasting real GDP growth for Africa
Potential modules


  *   run_simulation.py
* for 100 times per DGP specification: 
* estimate both models
* compare RMSPE
* create table
* export table

  *   model.py
* gather input: JH, CRDW, pos, neg
* estimate model
* rolling forecast
* forecast benchmark

  *   data.py
* simulate(N, T, alp, var)
* load and preprocess: test if right format for model estimation
* Y_growth

## Data Loading
We simulate N different time series of length T as follows
<formulas here>

However, to check and compare results we also load the real data of African countries.

### Loading African Data
"""

# import file from local machine
from google.colab import files
uploaded = files.upload()

africa = pd.read_csv('/content/africa_gdp_index_eva.csv', delimiter=';', header=0, thousands=None)
africa = africa.apply(lambda x: x.str.replace(',','.'))

africa

africa = africa.astype(float)
africa = africa.transpose()

africa = africa.to_numpy()

africa['chad'].plot();

africa['ghana'].plot();

(africa['ghana']-africa['chad']).plot();

africa['madagascar'].plot();

"""Below I am just trying a PCA on the data for the three countries to see what it does and get some intuition. I use a package but also code it manually and (luckily) the results are the same."""

from sklearn.preprocessing import StandardScaler
africa_st = StandardScaler().fit_transform(africa)

africa_st.shape

from sklearn.decomposition import PCA
pca = PCA(n_components=1)
principalComponents = pca.fit_transform(africa_st)

pca.get_params()

plt.plot(principalComponents)

pcar = np.linalg.eig(np.cov(africa_st.transpose()))

pcar[1][0]

red = np.matmul(africa_st, pcar[1][0])

np.sum(principalComponents+red)

plt.plot(red)

"""### Simulate Data
Create N different time series of length T
"""

# set seed for reproducibility
np.random.seed(1)

def growth_rate(x, steps=1):
  return x[steps:]-x[:-steps]

def create_DGP(N, T, alpha, var_eps):
  # Function that takes all necessary parameters and returns a simulated dataset [NxT]
  Y=np.random.rand(N, T)
  for i in range(N):
    Y[i, 0]=0
    theta = np.random.uniform(1, alpha, 1)
    for t in range(1, T):
      epsilon = np.random.normal(0, sqrt(var_eps), 1)
      Y[i, t]=theta+Y[i, t-1]+epsilon
  Y_growth = np.vstack([growth_rate(row) for row in Y])
  return Y, Y_growth

N = 50
T = 100
alpha = 1
var_eps = 0.5

Y, Y_growth  = create_DGP(N, T, alpha, var_eps)

fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))
fig.suptitle('Country 0: level and growth')
axes[0].plot(Y[0])
axes[0].set_title('GDP Level')
axes[0].set_xlabel('t')
axes[1].plot(Y_growth[0])
axes[1].set_title('GDP Growth')
axes[1].set_xlabel('t')
fig.tight_layout()

fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))
fig.suptitle('Average level and growth')
axes[0].plot(np.mean(Y, axis=0))
axes[0].set_title('GDP Level')
axes[0].set_xlabel('t')
axes[1].plot(np.mean(Y_growth, axis=0))
axes[1].set_title('GDP Growth')
axes[1].set_xlabel('t')
fig.tight_layout()

# unit tests for simulating DGP
assert np.mean(Y, axis = 0)[0] == 0 # start time series 0 at t=0
assert round(np.mean(Y_growth)) == (alpha+1)/2

"""### Split Sample

Split the sample T into T1 and T2  with T1=aT2, with a=1, 2, 5 or 10
"""

a = 1

T1_size = int((T*a)/(1+a))  

T1 = Y[:, 0:(T1_size)] # Rounding when casting float to int
T2 = Y[:, (T1_size):T]

np.mean(Y, axis=0)[T1_size:].shape

fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 5))
fig.suptitle('Test and train timeline')
axes[0, 0].plot(np.mean(Y, axis=0)[:T1_size])
axes[0, 0].set_title('Average GDP Level: train')
axes[0, 0].set_xlabel('train')
axes[1, 0].plot(np.mean(Y_growth, axis=0)[:T1_size])
axes[1, 0].set_title('Average GDP Growth: test')
axes[1, 0].set_xlabel('train')
axes[0, 1].plot(np.mean(Y, axis=0)[T1_size:])
axes[0, 1].set_title('Average GDP Level: test')
axes[0, 1].set_xlabel('test')
axes[1, 1].plot(np.mean(Y_growth, axis=0)[:T1_size])
axes[1, 1].set_title('Average GDP Growth: test')
axes[1, 1].set_xlabel('test')

fig.tight_layout()

# unit tests
mean_train_growth = round(np.mean(np.mean(Y_growth, axis=0)[:T1_size]))
mean_test_growth = round(np.mean(np.mean(Y_growth, axis=0)[T1_size:]))
assert mean_test_growth == mean_train_growth

"""## Model Building

### v Step 1: CRDW Test
y(i, t)= theta(i) + y(j, t) + w(j, t)
for j=1,..., I and j unequal to i. 

Compute residuals w(j, t) and create Cointegration Regression Durbin Watson (CRDW) test statistic as CRDW(j)=2(1-roh(j)) where roh is estimated first order autocorrelation of estimated residuals w(j).

Save regressor y(j, t) where CRDW(j)> tao for next round
"""

def CRDW(i, tao=0.4):
  """This function tests for cointegration
      Args:
        i (int): index of the country we are modeling
        tao (float): critical value (default = 0.4)

      Returns:
        JH (array): An array with the regressors (incl. self)

  """

  JH=Y[i]
  for j in range(N):
      if j!=i:
        y = Y[i]
        x = Y[j]
        x = sm.add_constant(x)

        model = sm.OLS(y, x)
        results = model.fit()
        CRDW_j = stats.stattools.durbin_watson(results.resid)
        if CRDW_j > tao:
          JH = np.vstack((JH, Y[j]))
  assert JH.shape[0]>0 # test if JH contains atleast self
  return JH

"""### x Step 2: Estimate Cointegration

create matrices with groeivoet, level
calculate S00 S11 S01 S10
calculate eigenvalues
first eigenvalue-> eigenvector is beta for cointegration relation
"""

def cointegration(JH_i):
    """Johansen estimation for cointegration between two time series
    Args:
        JH_i (array): output of CRDW test

    Returns:
        beta (array): eigenvector

    """
    S11 = np.cov(JH_i)
    S01 = np.cov(np.vstack([growth_rate(JH_i[0]), JH_i[1][1:]]))
    S10 = np.cov(np.vstack([JH_i[0][1:], growth_rate(JH_i[1])]))
    S00 = np.cov(np.vstack([ growth_rate(row) for row in JH_i ]))

    beta = np.linalg.eigh(S11-S10.dot(np.linalg.inv(S00)).dot(S01))[1][:, 0]
    return beta

beta = cointegration(CRDW(0))

"""### v Step 3: Rank Correlations"""

def correlation(i, kn=4, kp=4):
    """Feature selection based on pairwise correlation
    Args:
        i (int): index of the country we are modeling
        tao (float): critical value (default = 0.4)

    Returns:
        JH (array): An array with the regressors (incl. self)

    """
    corr_i = np.zeros(N)
    for j in range(N):
      corr_i[j] = pearsonr(Y_growth[i], Y_growth[j])[0]
    
    pos = Y_growth[np.argpartition(corr_i, -(kp+1))[-(kp+1):-1]]
    #pos = Y_growth[corr_i.argsort()[(kp+1):-1]]
    assert pos.shape == (kp, T-1)
    neg = Y_growth[corr_i.argsort()[:kn]]
    assert neg.shape == (kn, T-1)
    #neg = Y_growth[np.argpartition(correlation(7), -5)[-5:-1]]
    return pos, neg

N = 50
corr = np.ones([N, N])
for i in range(N):
  for j in range(N):
    corr[i, j] = pearsonr(Y_growth[i], Y_growth[j])[0]

import seaborn as sns
sns.heatmap(corr)

plt.plot(corr[25])

sns.heatmap(np.tril(corr))

plt.plot(np.mean(corr, axis=0))

np.mean(np.mean(corr, axis=0))

alpha = 5
var_eps = 1
N = 50
def test_corr(N, alpha, var_eps):
  X, X_growth = create_DGP(N, 100, alpha, var_eps)

  corr_X = np.ones([N, N])
  for i in range(N):
    for j in range(N):
      corr_X[i, j] = pearsonr(X_growth[i], X_growth[j])[0]
  return np.mean(corr_X)

for alpha in [1, 2, 3, 4, 5]:
  print(str(alpha) + ' alpha returns correlation : '+str(test_corr(50, alpha, 0.5)))
  
  print(str(alpha) + ' alpha returns correlation : '+str(test_corr(50, alpha, 1)))
for var_eps in [0.5, 0.7, 0.9, 1]:
  print(str(var_eps) + ' var_eps returns correlation : '+str(test_corr(50, 1, var_eps)))
  
  print(str(var_eps) + ' var_eps returns correlation : '+str(test_corr(50, 2, var_eps)))
  
  print(str(var_eps) + ' var_eps returns correlation : '+str(test_corr(50, 5, var_eps)))

"""## Where does this correlation come from?
expected variance of growth rate is (alpha-1)**2/12  from theta and 1 from epsilon

Somehow for different var_eps and alpha always around 0.02
"""

# ??
np.mean(corr_X)

"""### v Step 4: Define Model
For every country (row), we retrieve an array of correlated countries (rows) and an array of countries in the (potential) cointegration relation.

Steps involved:

  * Define function(independent, parameters)
*   parameter: mu, gamma, beta, alphas
*  independent vars: pos, neg, JH
*  rank = JH.shape[0]-1
*  returns fitted value: f(pos, neg, JH) = growth[y]

  *   Estimate parameters
* desired output = growth[y]
* input = pos[y], neg[y], CRDW[y]
* params: mu, gamma, beta, ...
* fit by NLS: minimize des_out - fit(params, indep)

  * Forecast
* Train to retrieve params per i, training set
* Predict one step ahead
* store RMSPE
"""

for i in range(1, 2):
  JH = CRDW(i, tao=0.7)
  country = Y_growth[i]
  pos, neg = correlation(i)
  # beta = cointegration(JH)

  if 0<JH.shape[0]<100:
    rank = JH.shape[0]-1
    JH_growth = np.vstack([growth_rate(row) for row in JH])

  else:
    rank = 0
    beta = np.array(1)
    JH_growth = growth_rate(JH)
  print('here rank '+str(rank))
  model(pos, neg, country, JH, rank)

(np.array([-1])).dot(JH_growth)

# TO-DO: check growth rates! country should be label only CHECK LATER
def model(pos, neg, country, JH, rank):
  mu = params['mu']
  alpha_self = params['alpha_self']
  alpha_pos = params['alpha_pos']
  alpha_neg = params['alpha_neg']
  theta_pos = params['theta_pos']
  theta_neg = params['theta_neg']
  gamma = params['gamma']
  #beta = params['beta']
  if rank > 0:
    beta = np.array([params['beta0']])
    for br in range(1, rank):
      beta = np.append(beta, params['beta'+str(br)])  
  if rank == 0:
    beta=np.array([-1])
      
  alpha_i_j_p = np.array([alpha_pos, alpha_pos*theta_pos, alpha_pos*(theta_pos**2), alpha_pos*(theta_pos**3)])
  alpha_i_j_n = np.array([alpha_neg, alpha_neg*theta_neg, alpha_neg*(theta_neg**2), alpha_neg*(theta_neg**3)])
  
  correlation = alpha_self * (country) + alpha_i_j_n.dot(neg) + alpha_i_j_p.dot(pos)
  
  cointegration = gamma*(- beta.dot(JH_growth))

  model = cointegration + correlation + mu

  return model

from lmfit import Model
mod = Model(model)

mod.param_names

# TO-DO: check growth rates! country should be label only CHECK LATER
def residual(params, pos, neg, country, JH, rank):
  mu = params['mu']
  alpha_self = params['alpha_self']
  alpha_pos = params['alpha_pos']
  alpha_neg = params['alpha_neg']
  theta_pos = params['theta_pos']
  theta_neg = params['theta_neg']
  gamma = params['gamma']
  #beta = params['beta']
  if rank > 0:
    beta = np.array([params['beta0']])
    for br in range(1, rank):
      beta = np.append(beta, params['beta'+str(br)])
  if rank == 0:
    beta=np.array([1])
      
  alpha_i_j_p = np.array([alpha_pos, alpha_pos*theta_pos, alpha_pos*(theta_pos**2), alpha_pos*(theta_pos**3)])
  alpha_i_j_n = np.array([alpha_neg, alpha_neg*theta_neg, alpha_neg*(theta_neg**2), alpha_neg*(theta_neg**3)])
  
  correlation = alpha_self * (country) + alpha_i_j_n.dot(neg) + alpha_i_j_p.dot(pos)
  
  cointegration = gamma*(country - beta.dot(JH_growth[]))

  model = cointegration + correlation + mu

  return country-model

JH_growth.shape

params = Parameters()

params.add('mu', value = 1)
params.add('alpha_self', value = 2)
params.add('alpha_pos', value = 2)
params.add('alpha_neg', value = 2)
params.add('theta_pos', value = 2)
params.add('theta_neg', value = 2)
params.add('gamma', value = 5)

# params.pretty_print()

for i in range(1, 6):
  JH = CRDW(i, tao=0.7)
  country = Y_growth[i]
  pos, neg = correlation(i)
  # beta = cointegration(JH)

  if 0<JH.shape[0]<100:
    rank = JH.shape[0]-1
    for br in range(rank):
      params.add('beta'+str(br), value = 2)
    print('here rank '+str(rank))
    JH_growth = np.vstack([growth_rate(row) for row in JH])

  else:
    rank = 0
    beta = np.array(1)
    JH_growth = growth_rate(JH)

  # params.pretty_print()
  out = minimize(residual, params, args=(pos, neg, country, JH, rank), method='leastsq')
  print(out.message)

out.params

"""### Step 5: Estimate Parameters (NLS)

NLS predict growth y_i on constant_i lagged growth correlated others and cointegration combinations
"""

out = minimize(residual, params, args=(pos, neg, country, JH, rank), method='leastsq')

out.message

# predict with fitted values

fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))
fig.suptitle('Residuals for i = 2, model comparison')
axes[0].plot(out.residual)
axes[0].set_title('Us')
axes[0].set_xlabel('t')
axes[1].plot(IMA_resid)
axes[1].set_title('IMA(1, 1)')
axes[1].set_xlabel('t')
fig.tight_layout()

IMA_model = ARIMA(Y[2], order=(0, 1, 1))
results = IMA_model.fit(trend='nc')
IMA_resid = results.resid
results.plot_predict()
results.summary()

"""#### Scipy optimize tests"""

from scipy.optimize import curve_fit
def func(cointegration, mu, alpha_self, alpha_i_j_p, alpha_i_j_n):
  correlation = alpha_self * Y[7] + alpha_i_j_n.dot(neg) + alpha_i_j_p.dot(pos)
  return cointegration + correlation + mu

popt, pcov = curve_fit(func, cointegration, Y[7])
popt

"""### v Step 6: Benchmark (IMA(1, 1))
https://towardsdatascience.com/arima-forecasting-in-python-90d36c2246d3
"""

from sklearn.metrics import mean_squared_error
def baseline(i):
  "function to estimate IMA using rolling window, returns MSPE"  
  train, test = T1[i], T2[i]
  history = [x for x in train]
  predictions = list()
  for t in range(len(test)):
    model = ARIMA(history, order=(0,1,1))
    model_fit = model.fit(disp=0)
    output = model_fit.forecast()
    yhat = output[0]
    predictions.append(yhat)
    obs = test[t]
    history.append(obs)
    #print('predicted=%f, expected=%f' % (yhat, obs))
  # MSE = mean_squared_error(test, predictions)
  return predictions

baseline(2)

def recursive_estimation(T1_size, T2=30, steps_ahead=1):
  i = 0
  for j in range(T2):
    train_data = Y[i][:(T1_size+j)]
    IMA_model = ARIMA(train_data, order=(0, 1, 1))
    results = IMA_model.fit(trend='nc')

    fc = IMA_model.predict(Y[i][T1+j+1])
    forecasts.append(fc)
    
    RMSPE = np.sqrt(np.mean(np.square(((Y[i][T-T2:] - forecasts) / Y[i][T-T2])), axis=0))
  return RMSPE

i = 0
T1=20
T2=30
steps_ahead=1
for j in range(T2):
  train_data = Y[i][:(T1+j)]
  IMA_model = ARIMA(train_data, order=(0, 1, 1))
  results = IMA_model.fit(trend='nc')

  fc = IMA_model.predict(Y[i][T1+j+1])
  forecasts.append(fc)
    
RMSPE = np.sqrt(np.mean(np.square(((Y[i][T-T2:] - forecasts) / Y[i][T-T2])), axis=0))

IMA_model = ARIMA(Y[0], order=(0, 1, 1))
results = IMA_model.fit(trend='nc')

results.plot_predict()
results.summary()

"""## Construct forecasts

Create recursively T2 1-step ahead forecasts for each country (i).

Compute Root Mean Squared Prediction Error

Count #times RMSPE (us) < RMSPE(IMA)
"""

def recursive_estimation(model, T1, T2, steps_ahead=1):
  for j in range(T2):
    train_data = Y[i][:(T1+j)]
    model_IMA = ARIMA(train_data, order=(0, 1, 1))
    results = IMA_model.fit(trend='nc')

    fc = IMA_model.predict(Y[i][T1+j+1])
    forecasts.append(fc)
    
    RMSPE = np.sqrt(np.mean(np.square(((Y[i][T-T2:] - forecasts) / Y[i][T-T2])), axis=0))
  return RMSPE

# test
RMSPE_us=[1, 1, 1, 1, 1, 1]
RMSPE_IMA=[2, 2, 2, 2, 2, 2]

def compare_models(RMSPE_IMA, RMSPE_us):
  for j in range(6):
    if (RMSPE_us[j]<RMSPE_IMA[i]):
      beaten+=1
  return beaten

"""# Main Script"""

# FUN
N = 8
T = 100
Y = create_DGP(N, T, 1, 1, 1)
count = 0
for i in range(50):
  if (0<CRDW(i).shape[0]<100):
    count += 1
  #correlation(i)
print('Total number of countries with cointegration rank r>0: {} / {}'.format(count, N))



[N, T] = Y.shape
for i in range(N):
  estimate_model(i)
  #RMSPE_IMA = estimate_model(i)

i = 7
JH = CRDW(i)
pos, neg = correlation(i)
beta = cointegration(JH)
country = Y_growth[i]
 # TO-DO: growth rates!

def residual(params, pos, neg, country, JH):
  mu = params['mu']
  alpha_self = params['alpha_self']
  alpha_pos = params['alpha_pos']
  alpha_neg = params['alpha_neg']
  theta_pos = params['theta_pos']
  theta_neg = params['theta_neg']
  gamma = params['gamma']
  #beta = params['beta']

  alpha_i_j_p = np.array([alpha_pos, alpha_pos*theta_pos, alpha_pos*(theta_pos**2), alpha_pos*(theta_pos**3)])
  alpha_i_j_n = np.array([alpha_neg, alpha_neg*theta_neg, alpha_neg*(theta_neg**2), alpha_neg*(theta_neg**3)])
  
  correlation = alpha_self * (country) + alpha_i_j_n.dot(neg) + alpha_i_j_p.dot(pos)
  
  cointegration = gamma*(country - beta.dot(JH[:, :-1])) # check if deleted right time var

  model = cointegration + correlation + mu
  return Y_growth[0]-model

params = Parameters()
params.add('mu', value = 1)
params.add('alpha_self', value = 2)
params.add('alpha_pos', value = 2)
params.add('alpha_neg', value = 2)
params.add('theta_pos', value = 2)
params.add('theta_neg', value = 2)
params.add('gamma', value = 5)
#params.add('beta', value=beta.all()) # number depends on resuls CRDW

minimiz = minimize(residual, params, args=(pos, neg, country, JH), method='leastsq')

minimiz.params.pretty_print()

def model(i, mu, alpha_self, alpha_pos, alpha_neg, theta_pos, theta_neg, gamma):
  JH = CRDW(i)
 # pos, neg = correlation(i)
  #beta = cointegration(JH)
  S11 = np.cov(JH_i)
  S01 = np.cov(np.vstack([growth_rate(JH_i[0]), JH_i[1][1:]]))
  S10 = np.cov(np.vstack([JH_i[0][1:], growth_rate(JH_i[1])]))
  S00 = np.cov(np.vstack([ growth_rate(row) for row in JH_i ]))

  beta = np.linalg.eigh(S11-S10.dot(np.linalg.inv(S00)).dot(S01))[1][:, 0]
  country = Y_growth[i]
  corr_i = np.zeros(N)
  for j in range(N):
    corr_i[j] = pearsonr(Y_growth[i], Y_growth[j])[0] # drop argmax for i=j (1)
        # absolute value, take highest 8
  
  pos = Y_growth[np.argpartition(corr_i, -5)[-5:-1]]
  assert pos.shape[0] == 4
  neg = Y_growth[corr_i.argsort()[:4]]
  assert neg.shape[0] == 4


  alpha_i_j_p = np.array([alpha_pos, alpha_pos*theta_pos, alpha_pos*(theta_pos**2), alpha_pos*(theta_pos**3)])
  alpha_i_j_n = np.array([alpha_neg, alpha_neg*theta_neg, alpha_neg*(theta_neg**2), alpha_neg*(theta_neg**3)])
  
  correlation = alpha_self * (country) + alpha_i_j_n.dot(neg) + alpha_i_j_p.dot(pos)
  beta = cointegration(JH)
  cointegration = gamma*(country - beta.dot(CRDW(i)[:, :-1])) # check if deleted right time var

  out = cointegration + correlation + mu
  return out

popt, pcov = curve_fit(model, 7, Y_growth[7])

CRDW(7).shape

y = Y_growth[7]
jh = CRDW(7)
p, n = correlation(7)

c = Y_growth[7]
gmodel = Model(model)
gmodel.fit(y, JH=jh, pos=p, neg=n, country=c)
#result = gmodel.fit(y, x=x, amp=5, cen=5, wid=1)

#print(result.fit_report())

JH = CRDW(i)
pos, neg = correlation(i)
beta = cointegration(JH)
country = Y_growth[i]
model = Model(model,independent_vars=['JH','pos', 'neg', 'beta', 'country'])

from lmfit import Model
model_us = Model(model)
model_us.independent_vars
model.independent_vars

model_us.eval(params, i=7)

model_us.fit(7, params)

pars = model.make_params(a=3, b=0.5)
mod = Model(myfunc)
mod.set_param_hint('a', value=1.0)
mod.set_param_hint('b', value=0.3, min=0, max=1.0)
pars = mod.make_params()

range_N=[50]
range_T=[50]
range_alpha=[2, 5, 10]
range_a=[1, 2, 5, 10]
range_var_eps=[0.5, 1]

results = { 'DGP': [], 'mean rank': []}

for var_eps in range_var_eps:
  for a in range_a:
    for alpha in range_alpha:
      for T in range_T:
        for N in range_N:
          #results['DGP'].append( 'N = '+ str(N) + ' T = '+ str(T)+' alpha = '+ str(alpha)+' a = '+ str(a)+' var_eps = '+ str(var_eps))
          rank_per_run = []
          for s in range(5):
            cointegration = 0
            number_runs = number_runs+1
            Y = create_DGP(N, T, alpha, a, var_eps)
            for i in range(N):
              r = 0
              if np.array_equal(CRDW(i, tao=0.4), Y[i]) == False:
                r = CRDW(i).shape[0]-1
                cointegration = cointegration + r
            rank_per_run.append(cointegration/N)
          results['DGP'].append( 'N = '+ str(N) + ' T = '+ str(T)+' alpha = '+ str(alpha)+' a = '+ str(a)+' var_eps = '+ str(var_eps))
          results['mean rank'].append(np.mean(rank_per_run))
          print(rank_per_run)

results = pd.DataFrame(results)

results

def run_simulation(N, T, alpha, a, var_eps, tao):
  Y = create_DGP(N, T, alpha, a, var_eps)

  for i in range(N):
    # Build single equation model
    JH = CRDW(i)
    # estimate cointegration relation (lin comb)
    pairwise_correlation(i)


    # Build IMA(1, 1) model
    model_IMA = ..


    RMSPE_us = recursive_estimation(model_us, T1, T2, steps_ahead=1)
    RMSPE_IMA = recursive_estimation(model_IMA, T1, T2, steps_ahead=1)

  return compare_models(RMSPE_IMA, RMSPE_us)

"""# Export Results"""

simulation_runs=1
N=100
T=100
alpha=1
a=1
var_eps=0.5
tao=0.4

results = pd.DataFrame()
for i in range(simulation_runs):
  results.append(run_simulation(N, T, alpha, a, var_eps, tao))
  
results.to_csv('EIRAP-results.csv')